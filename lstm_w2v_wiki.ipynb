{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"lstm_w2v_wiki.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"zEF2bVs21IoI"},"source":["# Emotion Classification in texts using LSTM and Word2Vec\n","\n","### Architecture: \n","(X) Text -> Embedding (W2V pretrained on wikipedia articles) -> Deep Network (LSTM/GRU) -> Fully connected (Dense) -> Output Layer (Softmax) -> Emotion class (Y)\n","\n","#### Embedding Layer\n","* Word Embedding is a representation of text where words that have the similar meaning have a similar representation. We will use 300 dimentional word vectors pre-trained on wikipedia articles. We can also train the w2v model with our data, however our dataset is quite small and trained word vectors might not be as good as using pretrained w2v.\n","\n","#### Deep Network\n","* Deep network takes the sequence of embedding vectors as input and converts them to a compressed representation. The compressed representation effectively captures all the information in the sequence of words in the text. The deep network part is usually an RNN or some forms of it like LSTM/GRU. The dropout can be added to overcome the tendency to overfit, a very common problem with RNN based networks.\n","\n","#### Fully Connected Layer\n","* The fully connected layer takes the deep representation from the RNN/LSTM/GRU and transforms it into the final output classes or class scores. This component is comprised of fully connected layers along with batch normalization and optionally dropout layers for regularization.\n","\n","#### Output Layer\n","* Based on the problem at hand, this layer can have either Sigmoid for binary classification or Softmax for both binary and multi classification output."]},{"cell_type":"markdown","metadata":{"id":"b6ANm6sj1IoQ"},"source":["## Workflow: \n","1. Import Data\n","2. Prepare the input data\n","3. Import pre-trained W2V\n","4. Create Neural Network Pipeline\n","5. Train The Model\n","6. Evaluate results\n","\n","\n","\n","👋  **Let's start** "]},{"cell_type":"markdown","metadata":{"id":"2-yphdVK1RIc"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpi2DX7a1Rhu","executionInfo":{"status":"ok","timestamp":1618172952520,"user_tz":360,"elapsed":289782,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"4dfa59e0-897c-44ee-92ff-9a56e2690ddf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c-Ig9ILR1IoR"},"source":["## 1. Import Data\n"]},{"cell_type":"code","metadata":{"id":"6v1VFDWM1IoR","executionInfo":{"status":"ok","timestamp":1618172971514,"user_tz":360,"elapsed":4008,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","# text preprocessing\n","from nltk.tokenize import word_tokenize\n","import re\n","\n","# plots and metrics\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","\n","# preparing input to our model\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","\n","# keras layers\n","from keras.models import Sequential\n","from keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"flcHJEQp1IoS"},"source":["Defining vector space dimension and fixed input size"]},{"cell_type":"code","metadata":{"id":"ivs7leMh1IoS","executionInfo":{"status":"ok","timestamp":1618172975282,"user_tz":360,"elapsed":269,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["# Number of labels: joy, anger, fear, sadness, neutral\n","num_classes = 5\n","\n","# Number of dimensions for word embedding\n","embed_num_dims = 300\n","\n","# Max input length (max number of words) \n","max_seq_len = 500\n","\n","class_names = ['joy', 'fear', 'anger', 'sadness', 'neutral']"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gmx361bi1zJg","executionInfo":{"status":"ok","timestamp":1618172977291,"user_tz":360,"elapsed":265,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["import os\n","os.chdir(\"/content/drive/MyDrive/nlp-text-emotion-master\")"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JXcAsJsA1IoT"},"source":["Importing our training and testing datasets"]},{"cell_type":"code","metadata":{"id":"vFxQEmGu1IoT","executionInfo":{"status":"ok","timestamp":1618172980386,"user_tz":360,"elapsed":1309,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["data_train = pd.read_csv('data_train.csv', encoding='utf-8')\n","data_test = pd.read_csv('data_test.csv', encoding='utf-8')\n","\n","X_train = data_train.Text\n","X_test = data_test.Text\n","\n","y_train = data_train.Emotion\n","y_test = data_test.Emotion\n","\n","data = data_train.append(data_test, ignore_index=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326},"id":"GQTu1BOX1IoT","executionInfo":{"status":"ok","timestamp":1618172981091,"user_tz":360,"elapsed":418,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"973e0ff5-dfa8-4531-d2e2-e0af4b29903b"},"source":["print(data.Emotion.value_counts())\n","data.head(6)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["joy        2326\n","sadness    2317\n","anger      2259\n","neutral    2254\n","fear       2171\n","Name: Emotion, dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotion</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>There are tons of other paintings that I thin...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sadness</td>\n","      <td>Yet the dog had grown old and less capable , a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fear</td>\n","      <td>When I get into the tube or the train without ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fear</td>\n","      <td>This last may be a source of considerable disq...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>She disliked the intimacy he showed towards so...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sadness</td>\n","      <td>When my family heard that my Mother's cousin w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotion                                               Text\n","0  neutral   There are tons of other paintings that I thin...\n","1  sadness  Yet the dog had grown old and less capable , a...\n","2     fear  When I get into the tube or the train without ...\n","3     fear  This last may be a source of considerable disq...\n","4    anger  She disliked the intimacy he showed towards so...\n","5  sadness  When my family heard that my Mother's cousin w..."]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"jxyZbFWH1IoU"},"source":["## 2. Prepare input data\n","To input the data to our NN Model we'll need some preprocessing:\n","1. Tokenize our texts and count unique tokens\n","2. Padding: each input (sentence or text) has to be of the same lenght\n","3. Labels have to be converted to integeres and categorized"]},{"cell_type":"markdown","metadata":{"id":"jEtPcUlA1IoV"},"source":["Basic preprocessing and tokenization using nltk to double check that sentences are properly split into words.\n","We could also add stopword removal but steps like stemming or lemmatization are not needed since we are using word2vec and words with the same stem can have a different meaning"]},{"cell_type":"code","metadata":{"id":"lTjOgyuf1IoV","executionInfo":{"status":"ok","timestamp":1618172984771,"user_tz":360,"elapsed":318,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["def clean_text(data):\n","    \n","    # remove hashtags and @usernames\n","    data = re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n","    data = re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n","    \n","    # tekenization using nltk\n","    data = word_tokenize(data)\n","    \n","    return data"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3XazvvRR1IoV"},"source":["*Making things easier for keras tokenizer 🙃"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NzS7UYUa1IoV","executionInfo":{"status":"ok","timestamp":1618172992037,"user_tz":360,"elapsed":5139,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"f106bcd3-0762-49eb-b578-efefd1364b44"},"source":["import nltk\n","nltk.download('punkt')\n","texts = [' '.join(clean_text(text)) for text in data.Text]\n","\n","texts_train = [' '.join(clean_text(text)) for text in X_train]\n","texts_test = [' '.join(clean_text(text)) for text in X_test]"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ANSTFRo1IoW","executionInfo":{"status":"ok","timestamp":1617992126687,"user_tz":360,"elapsed":435,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"51b98132-7849-4855-9450-75fd3bc4e2b8"},"source":["print(texts_train[92])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["a bit ? I 'm extremely annoyed that he did n't phone me when he promised me that he would ! He 's such a liar .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-4XKvm4p1IoW"},"source":["**Tokenization + fitting using keras**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQJ9_j3H1IoW","executionInfo":{"status":"ok","timestamp":1618173000298,"user_tz":360,"elapsed":738,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"ad380519-afa8-429b-b42c-a9183623c3c6"},"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","sequence_train = tokenizer.texts_to_sequences(texts_train)\n","sequence_test = tokenizer.texts_to_sequences(texts_test)\n","\n","index_of_words = tokenizer.word_index\n","\n","# vacab size is number of unique words + reserved 0 index for padding\n","vocab_size = len(index_of_words) + 1\n","\n","print('Number of unique words: {}'.format(len(index_of_words)))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Number of unique words: 12088\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wVsxCzb_1IoX"},"source":["**Padding** -> each input has the same length\n","\n","We defined maximun number of words for our texts and input size to our model has to be fixed - padding with zeros to keep the same input lenght (longest input in our dataset is ~250 words)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4Mp6Jhg1IoX","executionInfo":{"status":"ok","timestamp":1618173003565,"user_tz":360,"elapsed":498,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"426de688-8c94-45f4-b2cd-cd46afc9cd32"},"source":["X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len )\n","X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len )\n","\n","X_train_pad"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0,     0,     0, ...,   119,    51,   345],\n","       [    0,     0,     0, ...,    37,   277,   154],\n","       [    0,     0,     0, ...,    16,     2,  1210],\n","       ...,\n","       [    0,     0,     0, ...,   876,     4,   909],\n","       [    0,     0,     0, ...,     1,     6,   117],\n","       [    0,     0,     0, ..., 10259,   173,    13]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"GBUEX8tB1IoX"},"source":["**Categorize** labels: "]},{"cell_type":"code","metadata":{"id":"KQOHj8ze1IoY","executionInfo":{"status":"ok","timestamp":1618173005827,"user_tz":360,"elapsed":283,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["encoding = {\n","    'joy': 0,\n","    'fear': 1,\n","    'anger': 2,\n","    'sadness': 3,\n","    'neutral': 4\n","}\n","\n","# Integer labels\n","y_train = [encoding[x] for x in data_train.Emotion]\n","y_test = [encoding[x] for x in data_test.Emotion]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9CYy4nN1IoY","executionInfo":{"status":"ok","timestamp":1618173008291,"user_tz":360,"elapsed":273,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"6c25be27-e10a-4bd2-88d8-833a35da47a9"},"source":["y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","y_train"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 1.],\n","       [0., 0., 0., 1., 0.],\n","       [0., 1., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., 1., 0.],\n","       [0., 1., 0., 0., 0.],\n","       [0., 0., 1., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"IZZYQFXJ1IoY"},"source":["## 2. Import pretrained word vectors"]},{"cell_type":"markdown","metadata":{"id":"vFyB5uvr1IoZ"},"source":["* Importing pretrained word2vec from file and creating embedding matrix\n","* We will later map each word in our corpus to existing word vector"]},{"cell_type":"code","metadata":{"id":"pCQyhH6O1IoZ","executionInfo":{"status":"ok","timestamp":1618173011152,"user_tz":360,"elapsed":587,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["def create_embedding_matrix(filepath, word_index, embedding_dim):\n","    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","    with open(filepath) as f:\n","        for line in f:\n","            word, *vector = line.split()\n","            if word in word_index:\n","                idx = word_index[word] \n","                embedding_matrix[idx] = np.array(\n","                    vector, dtype=np.float32)[:embedding_dim]\n","    return embedding_matrix"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yV5jQ0uC1IoZ"},"source":["You can download and import any pre-trained word embeddings. I will use 300 dimentional w2v pre-trained on wikipedia articles. Download fast text english vectors: https://fasttext.cc/docs/en/english-vectors.html"]},{"cell_type":"code","metadata":{"id":"Y-c-U29s1Ioa","executionInfo":{"status":"ok","timestamp":1618173013958,"user_tz":360,"elapsed":341,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["import urllib.request\n","import zipfile\n","import os\n","\n","fname = 'embeddings/wiki-news-300d-1M.vec'\n","\n","if not os.path.isfile(fname):\n","    print('Downloading word vectors...')\n","    urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip',\n","                              'wiki-news-300d-1M.vec.zip')\n","    print('Unzipping...')\n","    with zipfile.ZipFile('wiki-news-300d-1M.vec.zip', 'r') as zip_ref:\n","        zip_ref.extractall('embeddings')\n","    print('done.')\n","    \n","    os.remove('wiki-news-300d-1M.vec.zip')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wju8G1ae1Ioa","executionInfo":{"status":"ok","timestamp":1618173060550,"user_tz":360,"elapsed":43999,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"4230b5c5-1905-403f-d530-4e1494ae7b33"},"source":["embedd_matrix = create_embedding_matrix(fname, index_of_words, embed_num_dims)\n","embedd_matrix.shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12089, 300)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"TDodbTXK1Ioa"},"source":["Some of the words from our corpus were not included in the pre-trained word vectors. If we inspect those words we'll see that it's mostly spelling errors. It's also good to double check the noise in our data f.e different languages or tokenizer errors."]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"GlhTHCbc1Iob","executionInfo":{"status":"ok","timestamp":1618173081206,"user_tz":360,"elapsed":398,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"1927f717-e088-4380-ab57-31407eadea37"},"source":["# Inspect unseen words\n","new_words = 0\n","\n","for word in index_of_words:\n","    entry = embedd_matrix[index_of_words[word]]\n","    if all(v == 0 for v in entry):\n","        new_words = new_words + 1\n","\n","print('Words found in wiki vocab: ' + str(len(index_of_words) - new_words))\n","print('New words found: ' + str(new_words))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Words found in wiki vocab: 11442\n","New words found: 646\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N3CYyGOw1Iob"},"source":["## 3. Create LSTM Pipeline"]},{"cell_type":"markdown","metadata":{"id":"M6GLQCTf1Iob"},"source":["### Embedding Layer\n","\n","We will use pre-trained word vectors. We could also train our own embedding layer if we don't specify the pre-trained weights \n","\n","* **vocabulary size:** the maximum number of terms that are used to represent a text: e.g. if we set the size of the “vocabulary” to 1000 only the first thousand terms most frequent in the corpus will be considered (and the other terms will be ignored)\n","* **the maximum length:** of the texts (which must all be the same length)\n","* **size of embeddings:** basically, the more dimensions we have the more precise the semantics will be, but beyond a certain threshold we will lose the ability of the embedding to define a coherent and general enough semantic area\n","* **trainable:** True if you want to fine-tune them while training\n"]},{"cell_type":"code","metadata":{"id":"8lmilfzC1Iob","executionInfo":{"status":"ok","timestamp":1618173084919,"user_tz":360,"elapsed":257,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["# Embedding layer before the actaul BLSTM \n","embedd_layer = Embedding(vocab_size,\n","                         embed_num_dims,\n","                         input_length = max_seq_len,\n","                         weights = [embedd_matrix],\n","                         trainable=False)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aB_c-t051Ioc"},"source":["### Model Pipeline\n","- the input is the first N words of each text (with proper padding)\n","- the first level creates embedding of words, using vocabulary with a certain dimension, and a given size of embeddings\n","- LSTM/GRU layer which will receive word embeddings for each token in the tweet as inputs. The intuition is that its output tokens will store information not only of the initial token, but also any previous tokens; In other words, the LSTM layer is generating a new encoding for the original input.\n","- the output level has a number of neurons equal to the classes of the problem and a “softmax” activation function"]},{"cell_type":"markdown","metadata":{"id":"eEdJSFEb1Ioc"},"source":["You can change GRU to LSTM. The results will be very similar but LSTM might take longer to train."]},{"cell_type":"code","metadata":{"id":"70Mv0kRC1Ioc","executionInfo":{"status":"ok","timestamp":1618173088098,"user_tz":360,"elapsed":1149,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}}},"source":["# Parameters\n","gru_output_size = 128\n","bidirectional = True\n","\n","# Embedding Layer, LSTM or biLSTM, Dense, softmax\n","model = Sequential()\n","model.add(embedd_layer)\n","\n","if bidirectional:\n","    model.add(Bidirectional(GRU(units=gru_output_size,\n","                              dropout=0.2,\n","                              recurrent_dropout=0.2)))\n","else:\n","     model.add(GRU(units=gru_output_size,\n","                dropout=0.2, \n","                recurrent_dropout=0.2))\n","\n","model.add(Dense(num_classes, activation='softmax'))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"seqxbwqi1Iod","executionInfo":{"status":"ok","timestamp":1618173091176,"user_tz":360,"elapsed":270,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"25473b14-5d4f-4e09-db38-5fa85d15b60b"},"source":["model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","model.summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 500, 300)          3626700   \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 256)               330240    \n","_________________________________________________________________\n","dense (Dense)                (None, 5)                 1285      \n","=================================================================\n","Total params: 3,958,225\n","Trainable params: 331,525\n","Non-trainable params: 3,626,700\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fwVsZflk1Iod"},"source":["## 3. Train the Model"]},{"cell_type":"markdown","metadata":{"id":"x6HPkefD1Iod"},"source":["* **validation data**: use validation_split in order to estimate how well your model has been trained and adjust parameters or add dropout layers. After that we will train the model using the complete train set.\n","* **epochs**: 15 **batch_size**: 128 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"id":"N52cBjRf1Iod","executionInfo":{"status":"error","timestamp":1618179688255,"user_tz":360,"elapsed":6595018,"user":{"displayName":"Sushitha Rajeev","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7kNw5W8-bqYUp7Sr2KO5ir6bPQppoX1MGVnGywTQ=s64","userId":"07402521688931106841"}},"outputId":"c76c8b3c-3b54-4d63-ebc7-e723740cb569"},"source":["batch_size = 128\n","epochs = 15\n","\n","hist = model.fit(X_train_pad, y_train, \n","                 batch_size=batch_size,\n","                 epochs=epochs,\n","                 validation_data=(X_test_pad,y_test))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","62/62 [==============================] - 494s 8s/step - loss: 1.5033 - accuracy: 0.3467 - val_loss: 1.2728 - val_accuracy: 0.4671\n","Epoch 2/15\n","62/62 [==============================] - 483s 8s/step - loss: 1.1573 - accuracy: 0.5423 - val_loss: 0.9612 - val_accuracy: 0.6384\n","Epoch 3/15\n","62/62 [==============================] - 493s 8s/step - loss: 0.9222 - accuracy: 0.6652 - val_loss: 0.8437 - val_accuracy: 0.6879\n","Epoch 4/15\n","62/62 [==============================] - 501s 8s/step - loss: 0.8086 - accuracy: 0.7068 - val_loss: 0.8088 - val_accuracy: 0.7050\n","Epoch 5/15\n","62/62 [==============================] - 487s 8s/step - loss: 0.7557 - accuracy: 0.7249 - val_loss: 0.7751 - val_accuracy: 0.7165\n","Epoch 6/15\n","62/62 [==============================] - 486s 8s/step - loss: 0.7466 - accuracy: 0.7311 - val_loss: 0.7653 - val_accuracy: 0.7230\n","Epoch 7/15\n","62/62 [==============================] - 492s 8s/step - loss: 0.7090 - accuracy: 0.7428 - val_loss: 0.7558 - val_accuracy: 0.7203\n","Epoch 8/15\n","62/62 [==============================] - 495s 8s/step - loss: 0.6618 - accuracy: 0.7635 - val_loss: 0.7519 - val_accuracy: 0.7259\n","Epoch 9/15\n","62/62 [==============================] - 494s 8s/step - loss: 0.6387 - accuracy: 0.7722 - val_loss: 0.7414 - val_accuracy: 0.7342\n","Epoch 10/15\n","62/62 [==============================] - 494s 8s/step - loss: 0.6219 - accuracy: 0.7810 - val_loss: 0.7362 - val_accuracy: 0.7318\n","Epoch 11/15\n","62/62 [==============================] - 489s 8s/step - loss: 0.6223 - accuracy: 0.7732 - val_loss: 0.7354 - val_accuracy: 0.7371\n","Epoch 12/15\n","62/62 [==============================] - 483s 8s/step - loss: 0.6065 - accuracy: 0.7882 - val_loss: 0.7355 - val_accuracy: 0.7321\n","Epoch 13/15\n","62/62 [==============================] - 489s 8s/step - loss: 0.5825 - accuracy: 0.7955 - val_loss: 0.7441 - val_accuracy: 0.7291\n","Epoch 14/15\n","27/62 [============>.................] - ETA: 4:25 - loss: 0.5924 - accuracy: 0.7807"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-83f8a43b51cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                  validation_data=(X_test_pad,y_test))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"0myDVsP11Ioe"},"source":["#  \"Accuracy\"\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()\n","\n","# \"Loss\"\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xWlxpGgy1Ioe"},"source":["## 4. Evaluation"]},{"cell_type":"code","metadata":{"id":"MfUPyc_r1Ioe"},"source":["predictions = model.predict(X_test_pad)\n","predictions = np.argmax(predictions, axis=1)\n","predictions = [class_names[pred] for pred in predictions]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6L_q-1Pr1Ioe"},"source":["print(\"Accuracy: {:.2f}%\".format(accuracy_score(data_test.Emotion, predictions) * 100))\n","print(\"\\nF1 Score: {:.2f}\".format(f1_score(data_test.Emotion, predictions, average='micro') * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OhcQFZ8M1Ioe"},"source":["#### Plotting confusion Matrix:"]},{"cell_type":"code","metadata":{"id":"W7z32Jkk1Iof"},"source":["def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    '''\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    '''\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    fig, ax = plt.subplots()\n","    \n","    # Set size\n","    fig.set_size_inches(12.5, 7.5)\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    ax.grid(False)\n","    \n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvKO7mtC1Iof"},"source":["print(\"\\nF1 Score: {:.2f}\".format(f1_score(data_test.Emotion, predictions, average='micro') * 100))\n","\n","# Plot normalized confusion matrix\n","plot_confusion_matrix(data_test.Emotion, predictions, classes=class_names, normalize=True, title='Normalized confusion matrix')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7jApTVJH1Iof"},"source":["#### Lets try other inputs:"]},{"cell_type":"code","metadata":{"id":"FoEItu7J1Iof"},"source":["print('Message: {}\\nPredicted: {}'.format(X_test[4], predictions[4]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aErRoXi_1Iog"},"source":["import time\n","\n","message = ['delivery was hour late and my pizza was cold!']\n","\n","seq = tokenizer.texts_to_sequences(message)\n","padded = pad_sequences(seq, maxlen=max_seq_len)\n","\n","start_time = time.time()\n","pred = model.predict(padded)\n","\n","print('Message: ' + str(message))\n","print('predicted: {} ({:.2f} seconds)'.format(class_names[np.argmax(pred)], (time.time() - start_time)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nvuiz3v91Iog"},"source":["# Done\n","Save the model for later use 🙃 "]},{"cell_type":"code","metadata":{"id":"TjYn-i301Iog"},"source":["# creates a HDF5 file 'my_model.h5'\n","model.save('models/biLSTM_w2v.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltcpW2Ch1Iog"},"source":["from keras.models import load_model\n","predictor = load_model('models/biLSTM_w2v.h5')"],"execution_count":null,"outputs":[]}]}